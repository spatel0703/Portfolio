<!-- blog_post1.html -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Implementing k-Nearest Neighbors (KNN) Classifier from Scratch</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <h1>Shrey V Patel</h1>
        <p>Data Science and Software</p>
    </header>

    <section id="blog-post">
        <h2>Implementing k-Nearest Neighbors (KNN) Classifier from Scratch</h2>

        <div class="content">
            <h3>Introduction</h3>
            <p>In the era of data science and machine learning, k-Nearest Neighbors (KNN) stands out as a simple yet powerful algorithm for classification tasks. This blog post will guide you through the process of creating a KNN classifier from scratch using Python. We will cover loading and exploring the dataset, performing Exploratory Data Analysis (EDA), and implementing the KNN algorithm step by step.

</p>
            <!-- Loading Data -->
            <h3>Loading Data</h3>
            <p>We begin by loading our dataset, which contains information related to diabetes. The data includes features such as codes and corresponding values. For simplicity, we focus on the third column ('Code'). We use pandas to read the CSV file and preprocess the data.</p>
            <pre>
                import numpy as np
                import matplotlib.pyplot as plt
                import pandas as pd

                diabetesdf = pd.read_csv('combined_dataset.csv', na_filter = False)

                #since we only need the 3rd column(Code), we will remove the Date and Time columns
                diabetesdf.drop(diabetesdf.columns[[0,1]], axis = 1, inplace=True)
                diabetesdf.to_csv('diabetesdf.csv', index=False)
                diabetesdf
            </pre>

            <h3>Exploratory Data Analysis</h3>
            <p>EDA helps us understand the dataset better. We check the shape, information, and tendencies of the data. Additionally, we visualize the occurrences of different codes and their correlation with values.</p>
            <pre>
                print("The shape of the dataset is: ", diabetesdf.shape)
                print("The information about the dataset: ", diabetesdf.info())

                #this gives the datasets tendencies
                diabetesdf.describe()

                #this finds the number of empty points in the dataset
                diabetesdf.isnull().sum()

                #this shows the how many rows of data there are
                print("Number of samples in this dataset are: ", len(diabetesdf))

                #this finds the unique values among the code column
                code_values = diabetesdf['Code'].unique()
                print("The unique values among the Code column are:", code_values)

                #this finds the unique values among the Value column
                unique_values = diabetesdf['Value'].unique()
                print("The unique numbers from the Value column are:", unique_values)

                #this counts the number of occurences for each unique Code value
                diabetesdf['Code'].value_counts()

                diabetesdf['Value'].value_counts()

                #this graph shows the number of occurences for the Code value on a bar graph

                code_counts = diabetesdf['Code'].value_counts()

                plt.figure(figsize = (8,6))
                plt.bar(code_counts.index, code_counts, color = 'r')
                plt.title('Code Number of Occurences')
                plt.xlabel('Code')
                plt.ylabel('Number of Occurences')
                plt.show()

                import seaborn as sns

                #this plot shows the correlation between a Code occurence and its output Value
                plt.figure(figsize = (10,8))
                sns.stripplot(x = 'Code', y = 'Value', data = diabetesdf.head(300), palette = 'viridis')
                plt.title('Code vs Value Stripplot')
                plt.xlabel('Code')
                plt.ylabel('Value')
                plt.show()
            </pre>

            <h3>Converting the 'Code' column to one-hot encoding</h3>
            <p>To prepare our data for KNN, we convert the 'Code' column into one-hot encoding. This step ensures that the algorithm considers categorical values appropriately.</p>
            <pre>
                #this turns the original dataframe into a one-hot encoded one. Value remains same for each row.
                #However, code only returns 1 if true for the Code column
                diabetes_one_hot_data = pd.get_dummies(diabetesdf, columns = ['Code'])
                diabetes_one_hot_data.to_csv('diabetes_one_hot_dataknn.csv', index=False)
                diabetes_one_hot_data
            </pre>

            <h3>60-10-30% Training-Validation-Test Set Split</h3>
            <p>We split the dataset into training, validation, and test sets with a 60-10-30% split ratio.</p>
            <pre>
            <!-- Paste your multiline code here -->
            <!-- Each line of code should be indented -->
                from sklearn.model_selection import train_test_split

                #this splits the training-validation-test sets into a 60-10-30% split
                train_data, temp_data = train_test_split(diabetes_one_hot_data, test_size=0.4, random_state=42)
                valid_data, test_data = train_test_split(temp_data, test_size=0.75, random_state=42)

                #this splits the features
                X_train = train_data.drop('Value', axis=1)
                X_valid = valid_data.drop('Value', axis=1)
                X_test = test_data.drop('Value', axis=1)

                #this splits the Value variable since it is the target
                y_train = train_data['Value']
                y_valid = valid_data['Value']
                y_test = test_data['Value']

                #prints out shape of sets
                print("Training set shape:", X_train.shape, y_train.shape)
                print("Validation set shape:", X_valid.shape, y_valid.shape)
                print("Test set shape:", X_test.shape, y_test.shape)

                #this will return the dataframes for the training-validation-test sets
                train_data
                valid_data
                test_data
            </pre>


            <h3>KNN Algorithm</h3>
            <p>In our KNN algorithm implementation, the `euclidean_distance` function is fundamental, computing the Euclidean distance between two instances. This distance metric measures the straight-line distance between two points in Euclidean space. The function takes two arrays, `instance1` and `instance2`, representing the feature vectors of the instances. The calculation involves finding the squared differences between corresponding elements, summing them up, and finally taking the square root.

Moving on to the `knn_predict` function, its purpose is to predict target values for test instances based on their k-nearest neighbors in the training data. The function takes training data, a target column, and test data as inputs, along with parameters such as the number of neighbors (k) and a subsample fraction for efficiency. The algorithm iterates over each test instance and training instance, calculating the Euclidean distance for each pair. The distances are stored along with their corresponding target values in the `current_distances` list, which is then sorted to identify the k-nearest neighbors.

The `counts` dictionary tallies the occurrences of each target value among the selected neighbors. The final predictions are yielded as dictionaries containing the counts, true values, and row numbers. In the subsequent loop that iterates over the yielded results, the predicted value is determined as the one with the maximum count among the neighbors. Each prediction is then printed, displaying the predicted value, true value, and the row number.

Understanding these intricacies, particularly the role of Euclidean distance in determining proximity and the selection of neighbors, provides a comprehensive insight into the functioning of the KNN algorithm.</p>
            <pre>
                import numpy as np
                from tqdm import tqdm

                #this calculates the euclidian_distance between two instances
                def euclidean_distance(instance1, instance2):
                    return np.sqrt(np.sum((instance1 - instance2) ** 2))

                #this function takes the training data, Value as the target column, and the test data as inputs with 5 as a hyperparameter
                #this will find the nearest neighbors and then predict the value based on those nearest neighbors
                def knn_predict(train_data, target_column, data, k=5, subsample_fraction=0.1, num_rows_to_predict=8799):

                    test_data_subsample = data.iloc[:num_rows_to_predict, :]

                    distances = []

                    #the reason for using tdqm was to track the progress of the predicition since there are a lot of rows
                    for row_number, (_, test_instance) in enumerate(tqdm(test_data_subsample.iterrows(), total=len(test_data_subsample), desc="Predicting")):
                        current_distances = []

                        #this will use the euclidian distance function to calculate the test_data instance and training_data instance
                        for i, train_instance in train_data.iterrows():
                            distance = euclidean_distance(test_instance[1:], train_instance[1:])
                            current_distances.append((distance, train_instance[target_column]))

                        #this piece of code will sort the distance determine the nearest neighbor
                        current_distances.sort(key=lambda x: x[0])
                        neighbors = current_distances[:k]

                        counts = {}
                        for neighbor in neighbors:
                            counts[neighbor[1]] = counts.get(neighbor[1], 0) + 1

                        #this will return the row number
                        yield counts, int(test_instance[target_column]), row_number

                for probs, true_value, row_number in knn_predict(train_data, 'Value', test_data, k=5, subsample_fraction=0.1, num_rows_to_predict=8799):
                    predicted_value = max(probs, key=probs.get)
                    print(f"Predicted Value: {predicted_value}, True Value: {true_value}, Prediction for row number {row_number}")
            </pre>
            <h3>Model Evaluation</h3>
            <p>In the model evaluation phase, we go beyond mere predictions and delve into assessing the performance of our KNN classifier. The knn_evaluate function serves as the cornerstone for this analysis. By employing a subsample of the test data, computational efficiency is maintained without sacrificing the evaluative power of the model.

The function iterates over different values of k, calculating various metrics such as accuracy, precision, recall, and F1 scores. For each k value, the loop traverses through the test instances, determining the nearest neighbors and predicting values. The counts of true positives, false positives, and other metrics are tracked, providing a detailed account of the model's predictive accuracy.

Furthermore, the precision, recall, weighted F1, and macro F1 scores are computed for an in-depth evaluation. These metrics offer insights into the classifier's ability to correctly identify positive instances, its overall effectiveness, and the balance between precision and recall.

The true labels and predicted labels are compared, and the precision, recall, and F1 scores are calculated using scikit-learn's metrics module. The weighted F1 score is particularly valuable as it considers the imbalance in class distribution. The results, including true positives, false positives, and a comprehensive set of evaluation metrics, are meticulously printed for the first two rows of predictions.

Concluding the model evaluation, a plot is generated, illustrating the relationship between different k values and the corresponding accuracy. This visual representation aids in identifying the optimal k value that maximizes the model's performance. The meticulous evaluation process provides a holistic understanding of the KNN classifier's strengths and areas for improvement, fostering informed decision-making in model selection and parameter tuning.</p>
            <pre>
                from tqdm import tqdm
                from sklearn.metrics import precision_score, recall_score, f1_score


                #I made another knn function to find the accuracy of the data but I only chose the first 2 rows of the test_data to predict
                #this is due to the fact that my computer could not handle running so much
                def knn_predict(train_data, target_column, data, k_values=[3, 5, 7], subsample_fraction=0.1, num_rows_to_predict=2):
                    # Subsample the test data
                    test_data_subsample = data.iloc[:num_rows_to_predict, :]

                    results = {'true_positives': 0, 'false_positives': 0, 'true_negatives': 0, 'false_negatives': 0}

                    k_vs_accuracy = {'k_values': [], 'accuracies': []}

                    for k in k_values:
                        accuracies = []

                        #this code is the same as the last knn predicition function, just uses tqdm for progress tracking
                        for row_number, (_, test_instance) in enumerate(tqdm(test_data_subsample.iterrows(), total=len(test_data_subsample), desc=f"Predicting (k={k})")):
                            current_distances = []

                            for i, train_instance in train_data.iterrows():
                                distance = euclidean_distance(test_instance[1:], train_instance[1:])
                                current_distances.append((distance, train_instance[target_column]))

                            current_distances.sort(key=lambda x: x[0])
                            neighbors = current_distances[:k]

                            counts = {}
                            for neighbor in neighbors:
                                counts[neighbor[1]] = counts.get(neighbor[1], 0) + 1

                            predicted_value = max(counts, key=counts.get)

                            if row_number < 2:
                                true_value = int(test_instance[target_column])
                                if predicted_value == true_value:
                                    results['true_positives'] += 1
                                else:
                                    results['false_positives'] += 1

                            #this will calculate the accuracy of the predictions for the first 2 rows
                            accuracies.append(1 if predicted_value == int(test_instance[target_column]) else 0)

                        #calculates overall accuracies according to k values
                        accuracy = sum(accuracies) / len(accuracies)
                        k_vs_accuracy['k_values'].append(k)
                        k_vs_accuracy['accuracies'].append(accuracy)

                    #this calculates the precision, recall, weighted F1, and macro F1
                    true_labels = [str(test_instance[target_column]) for _, test_instance in test_data_subsample.iterrows()]
                    predicted_labels = []
                    for _, test_instance in test_data_subsample.iterrows():
                        current_distances = []

                        for i, train_instance in train_data.iterrows():
                            distance = euclidean_distance(test_instance[1:], train_instance[1:])
                            current_distances.append((distance, str(train_instance[target_column])))

                        current_distances.sort(key=lambda x: x[0])
                        neighbors = current_distances[:k]

                        counts = {}
                        for neighbor in neighbors:
                            counts[neighbor[1]] = counts.get(neighbor[1], 0) + 1

                        predicted_value = max(counts, key=counts.get)
                        predicted_labels.append(predicted_value)


                    precision = precision_score(true_labels, predicted_labels, average='weighted')
                    recall = recall_score(true_labels, predicted_labels, average='weighted')
                    weighted_f1 = f1_score(true_labels, predicted_labels, average='weighted')
                    recall_f1 = f1_score(true_labels, predicted_labels, average='macro')

                    print("Results for the first 2 rows:")
                    print(results)
                    print("\nMetrics for the first 2 rows:")
                    print(f"Precision: {precision}, Recall: {recall}, Weighted F1: {weighted_f1}, Recall F1: {recall_f1}")

                    return results, k_vs_accuracy

                results, k_vs_accuracy = knn_predict(train_data, 'Value', test_data, k_values=[3, 5, 7], subsample_fraction=0.1, num_rows_to_predict=2)

                #this plots the k parameter vs accuracy graph
                plt.plot(k_vs_accuracy['k_values'], k_vs_accuracy['accuracies'], marker='o')
                plt.title('k vs Accuracy')
                plt.xlabel('k values')
                plt.ylabel('Accuracy')
                plt.show()

            </pre>

            <h3>Conclusion</h3>
            <p>In this blog post, we walked through the implementation of a KNN classifier from scratch, covering data loading, EDA, and the KNN algorithm. The code snippets provided enable you to understand the inner workings of the algorithm. Experimenting with different k values and evaluating model performance will enhance your understanding of the KNN algorithm.
            If you wish to see the results, be sure to visit my Github where I have this project and other pieces of work located.</p>
        </div>
    </section>

    <footer>
        <a href="blog.html">Back to Blog</a>
    </footer>
</body>
</html>
l>